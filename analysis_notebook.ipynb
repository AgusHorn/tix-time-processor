{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzer Notebook\n",
    "## Introduction\n",
    "This notebook contains code and graphs intended for exploratory analysis over the data and how the current `tix-time-processor` handles it. By no means should it be used as a testing method for the code, only to understand how the analysis are made and to improve further the results.\n",
    "\n",
    "### Disclaimer \n",
    "We understand that having a Python Notebook inside a functioning service is wrong. This should be in another repository, with its own versioning and such. But such is life... This will be left like this for the moment until someone with more time can fix it. Kind regards.\n",
    "\n",
    "### How to use this notebook\n",
    "For the moment, the notebook should live in the root directory of the sourcecode repository such as it is now. Also, there should be a directory next to this by the name of `batch-test-reports`, which it should contain the data to analyze. It is **strongly** recommended that the data is split among directories containing the expected processing input for an specific moment in time. This is to better understand the processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Analysis\n",
    "We will first setup everything in order to then run the code. Once the code was run, we will analyze with graphics how is it that we got to the show result\n",
    "### The setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:45:40.132927Z",
     "start_time": "2017-11-27T02:45:40.111775Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/fmartinez/workspaces/personal/tix-time-processor/batch-test-reports/1511633889/failed-results'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-4b4089f20662>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mpprinter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPrettyPrinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mreports_directory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch-test-reports'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'1511633889'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mreports_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReportHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreports_directory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobs_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreports_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_ip_and_processable_observations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mip\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mobs_set\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/workspaces/personal/tix-time-processor/processor/reports.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, installation_dir_path)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed_results_dir_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstallation_dir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFAILED_RESULTS_DIR_NAME\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed_results_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailed_results_dir_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreports_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__processable_reports\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/fmartinez/workspaces/personal/tix-time-processor/batch-test-reports/1511633889/failed-results'"
     ]
    }
   ],
   "source": [
    "# This will be a matplotlib notebook\n",
    "%matplotlib notebook\n",
    "# We import all the dependencies here\n",
    "from functools import partial\n",
    "from os import getcwd\n",
    "from os.path import join\n",
    "\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from processor import analysis, reports\n",
    "import pandas as pd\n",
    "\n",
    "# And setup the basic stuff, configure the pretty printer, load the reports, setup the analyzer and\n",
    "# define some more stuff.\n",
    "pprinter = pprint.PrettyPrinter(indent=2)\n",
    "reports_directory = join(getcwd(), 'batch-test-reports', '1511633889')\n",
    "reports_handler = reports.ReportHandler(reports_directory)\n",
    "ip, obs_set = reports_handler.get_ip_and_processable_observations()\n",
    "if ip is None and obs_set is None:\n",
    "    raise ValueError('No enough processable reports in directory {}'.format(reports_directory))\n",
    "analyzer = analysis.Analyzer(obs_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:19:54.000855Z",
     "start_time": "2017-11-27T02:19:53.975515Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_bins_and_bins_probabilities_dfs(histogram, probabilities_name='probabilities'):\n",
    "    bins_df = pd.DataFrame([{'min_value': bin_.min_value,\n",
    "                             'mid_value': bin_.mid_value,\n",
    "                             'max_value': bin_.max_value,\n",
    "                             'width': bin_.width,\n",
    "                             'data_points_qty': len(bin_.data)}\n",
    "                            for bin_ in histogram.bins])\n",
    "    bins_probabilities_normalized_df = pd.DataFrame(histogram.bins_probabilities,\n",
    "                                                    columns=[probabilities_name]) * (10 ** 8)\n",
    "    bins_probabilities_df = pd.concat([bins_probabilities_normalized_df, \n",
    "                                       bins_df['mid_value']],\n",
    "                                      axis=1)\n",
    "    return bins_df, bins_probabilities_df\n",
    "\n",
    "def plot_histogram_and_pdf(fig, axs, fixed_size_bin_histogram, histogram_name, logy=True, logx=True):\n",
    "    bins_df, bins_probabilities_df = get_bins_and_bins_probabilities_dfs(fixed_size_bin_histogram, histogram_name)\n",
    "    data = [fixed_size_bin_histogram.characterization_function(d) \n",
    "            for d in fixed_size_bin_histogram.data]\n",
    "    ranges = [b.min_value for b in fixed_size_bin_histogram.bins]\n",
    "    ranges.append(fixed_size_bin_histogram.bins[-1].max_value)\n",
    "    axs[0].hist(data, bins=ranges, edgecolor='black')\n",
    "    # upstream_bins_df.plot.bar('mid_value', 'width', logy=True, ax=axs[0])\n",
    "    bins_probabilities_df.plot('mid_value', histogram_name, \n",
    "                               logy=True, \n",
    "                               logx=True, \n",
    "                               ax=axs[1])\n",
    "    axs[1].axvline(fixed_size_bin_histogram.mode, color='green', label='mode')\n",
    "    axs[1].axvline(fixed_size_bin_histogram.threshold, color='red', label='threshold')\n",
    "    axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.588136Z",
     "start_time": "2017-11-27T02:10:47.871Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Finally we print the results... This is what is expected to go to the API\n",
    "pprinter.pprint(analyzer.get_results())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The RTT Histogram and the clock correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.588848Z",
     "start_time": "2017-11-27T02:10:47.877Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "plot_histogram_and_pdf(fig, axs, analyzer.rtt_histogram, 'rtt_probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.589618Z",
     "start_time": "2017-11-27T02:10:47.880Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "{'tau': analyzer.rtt_histogram.mode, 'tau_threshold': analyzer.rtt_histogram.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clock Fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.590230Z",
     "start_time": "2017-11-27T02:10:47.884Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# phis_timestamps, phis = tuple(zip(*analyzer.clock_fixer.phis_for_minute))\n",
    "fig, ax = plt.subplots()\n",
    "# regression_values = [analyzer.clock_fixer.slope * ts + analyzer.clock_fixer.intercept for ts in phis_timestamps]\n",
    "\n",
    "# ax.plot(phis_timestamps, regression_values, '-', color='red', label='regression')\n",
    "# ax.legend()\n",
    "obs_timestamps, rtts = tuple(zip(*[(o.day_timestamp, analysis.observation_rtt_key_function(o)) \n",
    "                                   for o in analyzer.clock_fixer.observations]))\n",
    "ax.scatter(obs_timestamps, rtts, s=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.590926Z",
     "start_time": "2017-11-27T02:10:47.888Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "obs_by_day_timestamp = sorted(analyzer.observations, key=lambda o: o.day_timestamp)\n",
    "y, x = tuple(zip(*[(analyzer.clock_fixer.phi_function(o.day_timestamp), o.day_timestamp)\n",
    "                   for o in obs_by_day_timestamp]))\n",
    "\n",
    "ax.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.591588Z",
     "start_time": "2017-11-27T02:10:47.890Z"
    }
   },
   "outputs": [],
   "source": [
    "rtts = [analysis.observation_rtt_key_function(o) for o in analyzer.clock_fixer.observations]\n",
    "max_rtt = max(rtts)\n",
    "min_rtt = min(rtts)\n",
    "min_rtt/10**9, max_rtt/10**9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.592314Z",
     "start_time": "2017-11-27T02:10:47.893Z"
    }
   },
   "outputs": [],
   "source": [
    "# {'slope': analyzer.clock_fixer.slope, 'intercept': analyzer.clock_fixer.intercept}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.592971Z",
     "start_time": "2017-11-27T02:10:47.895Z"
    }
   },
   "outputs": [],
   "source": [
    "# {'r_value': analyzer.clock_fixer.r_value, 'p_value': analyzer.clock_fixer.p_value, 'std_err': analyzer.clock_fixer.std_err}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.593587Z",
     "start_time": "2017-11-27T02:10:47.899Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "plot_histogram_and_pdf(fig, axs, analyzer.usage_calculator.upstream_histogram, 'upstream_probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.594401Z",
     "start_time": "2017-11-27T02:10:47.904Z"
    }
   },
   "outputs": [],
   "source": [
    "{'upstream mode': analyzer.usage_calculator.upstream_histogram.mode,\n",
    " 'upstream threshold': analyzer.usage_calculator.upstream_histogram.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dowstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.595215Z",
     "start_time": "2017-11-27T02:10:47.907Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "plot_histogram_and_pdf(fig, axs, analyzer.usage_calculator.downstream_histogram, 'downstream_probabilities')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-11-27T02:10:48.595815Z",
     "start_time": "2017-11-27T02:10:47.909Z"
    }
   },
   "outputs": [],
   "source": [
    "{'downstream mode': analyzer.usage_calculator.downstream_histogram.mode,\n",
    " 'downstream threshold': analyzer.usage_calculator.downstream_histogram.threshold}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality and Hurst values\n",
    "#### Quality"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tix-time-processing",
   "language": "python",
   "name": "tix-time-processing"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
